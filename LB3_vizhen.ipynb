{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOKns7vCnilNK8OmW5dWPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreyPaldin/CV_LB3/blob/main/LB3_vizhen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woP03t-8f_RU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b149e3c-5fde-41b5-af80-cbd9f11227be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Cloning into 'CV_LB3'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 35 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 52.31 MiB | 20.89 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python opencv-python-headless\n",
        "!git clone https://github.com/GreyPaldin/CV_LB3.git\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.ndimage import label\n",
        "from collections import deque\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обнаружить объект на однородном фоне, вести его по видео. Можно рисовать траекторию движения объекта каждый кадр (доп фича)."
      ],
      "metadata": {
        "id": "zhg2BnWdgIQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Надо пробовать на нормальном видео (прототип (не актуальный))\n",
        "\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from collections import deque\n",
        "\n",
        "def rgb_to_grayscale(img):\n",
        "    \"\"\"Собственная реализация RGB to grayscale\"\"\"\n",
        "    return (img[:,:,0]*0.299 + img[:,:,1]*0.587 + img[:,:,2]*0.114).astype(np.uint8)\n",
        "\n",
        "def frame_diff(prev, curr, threshold=25):\n",
        "    \"\"\"Разница кадров с пороговой обработкой\"\"\"\n",
        "    diff = np.abs(prev.astype(int) - curr.astype(int))\n",
        "    return (diff > threshold).astype(np.uint8) * 255\n",
        "\n",
        "def process_video(input_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Выходные видео\n",
        "    trajectory_writer = cv2.VideoWriter('trajectory.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    object_writer = cv2.VideoWriter('object.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    prev_gray = None\n",
        "    trajectory = deque(maxlen=60)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Собственное преобразование в grayscale\n",
        "        gray = rgb_to_grayscale(frame)\n",
        "\n",
        "        # Всегда инициализируем object_frame\n",
        "        object_frame = np.zeros_like(frame)\n",
        "\n",
        "        if prev_gray is not None:\n",
        "            # Разница кадров (собственная реализация)\n",
        "            diff = frame_diff(prev_gray, gray)\n",
        "\n",
        "            # Замена морфологических операций на OpenCV\n",
        "            kernel = np.ones((5,5), np.uint8)\n",
        "            closed = cv2.morphologyEx(diff, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "            # Замена поиска связных компонент на OpenCV\n",
        "            contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if contours:\n",
        "                # Используем OpenCV для выпуклой оболочки\n",
        "                largest = max(contours, key=cv2.contourArea)\n",
        "                hull = cv2.convexHull(largest)\n",
        "\n",
        "                # Создаем маску объекта\n",
        "                full_mask = np.zeros_like(closed)\n",
        "                cv2.drawContours(full_mask, [hull], -1, 255, -1)\n",
        "\n",
        "                # Копируем объект на черный фон\n",
        "                object_frame[full_mask == 255] = frame[full_mask == 255]\n",
        "\n",
        "                # Вычисляем центр масс\n",
        "                M = cv2.moments(largest)\n",
        "                if M[\"m00\"] > 0:\n",
        "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "                    trajectory.append((cx, cy))\n",
        "\n",
        "                    # Рисуем траекторию\n",
        "                    for i in range(1, len(trajectory)):\n",
        "                        cv2.line(frame, trajectory[i-1], trajectory[i], (255,0,0), 2)\n",
        "\n",
        "                    # Рисуем контур объекта\n",
        "                    cv2.drawContours(frame, [hull], -1, (0,255,0), 2)\n",
        "\n",
        "        # Записываем кадры\n",
        "        object_writer.write(object_frame)\n",
        "        trajectory_writer.write(frame)\n",
        "        prev_gray = gray.copy()\n",
        "\n",
        "    cap.release()\n",
        "    trajectory_writer.release()\n",
        "    object_writer.release()\n",
        "\n",
        "# Загружаем видео\n",
        "input_filename = '/content/drive/MyDrive/Мышка2.mp4'\n",
        "process_video(input_filename)\n",
        "\n",
        "# Скачивание результатов\n",
        "files.download('trajectory.mp4')\n",
        "files.download('object.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "i50njYa6Sfg6",
        "outputId": "70387b1d-9898-4fd9-c896-6fb6b38ccb05",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2965d73-22ec-4b8e-a754-99e25df3b637\", \"trajectory.mp4\", 10964758)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7faa503-ea2e-4257-a942-f5d76168e4b3\", \"object.mp4\", 1815819)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Метод для видео 1\n",
        "!pip install opencv-python\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from collections import deque\n",
        "import math\n",
        "from scipy.ndimage import label\n",
        "\n",
        "def rgb_to_grayscale(img):\n",
        "    return (img[:,:,0]*0.299 + img[:,:,1]*0.587 + img[:,:,2]*0.114).astype(np.uint8)\n",
        "\n",
        "def frame_diff(prev, curr, threshold=25):\n",
        "    diff = np.abs(prev.astype(int) - curr.astype(int))\n",
        "    return (diff > threshold).astype(np.uint8) * 255\n",
        "\n",
        "def process_video(input_path,\n",
        "                 max_line_length=100,\n",
        "                 min_object_area=200,\n",
        "                 max_object_area=5000,\n",
        "                 detection_region_y=None):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Ошибка открытия видеофайла\")\n",
        "        return\n",
        "\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    trajectory_writer = cv2.VideoWriter('trajectory.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    object_writer = cv2.VideoWriter('object.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    prev_gray = None\n",
        "    full_trajectory = []  # Хранит все точки траектории\n",
        "    current_segment = []   # Текущий непрерывный сегмент\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.GaussianBlur(rgb_to_grayscale(frame), (5,5), 0)\n",
        "\n",
        "        object_frame = np.zeros_like(frame)\n",
        "\n",
        "        if prev_gray is not None:\n",
        "            diff = frame_diff(prev_gray, gray)\n",
        "            #cv2_imshow(diff)\n",
        "\n",
        "            # Ограничиваем область детекции\n",
        "            if detection_region_y is not None:\n",
        "                mask = np.zeros_like(diff)\n",
        "                mask[detection_region_y:, :] = 255\n",
        "                diff = cv2.bitwise_and(diff, mask)\n",
        "\n",
        "            kernel = np.ones((5,5), np.uint8)\n",
        "            closed = cv2.morphologyEx(diff, cv2.MORPH_CLOSE, kernel)\n",
        "            contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if contours:\n",
        "                # Фильтрация контуров по площади\n",
        "                valid_contours = []\n",
        "                for cnt in contours:\n",
        "                    area = cv2.contourArea(cnt)\n",
        "                    if min_object_area <= area <= max_object_area:\n",
        "                        valid_contours.append(cnt)\n",
        "\n",
        "                if valid_contours:\n",
        "                    largest = max(valid_contours, key=cv2.contourArea)\n",
        "                    hull = cv2.convexHull(largest)\n",
        "                    full_mask = np.zeros_like(closed)\n",
        "                    cv2.drawContours(full_mask, [hull], -1, 255, -1)\n",
        "\n",
        "                    # Копируем объект на черный фон\n",
        "                    object_frame[full_mask == 255] = frame[full_mask == 255]\n",
        "\n",
        "                    # Вычисляем момент и центр масс\n",
        "                    M = cv2.moments(largest)\n",
        "                    if M[\"m00\"] > 0:\n",
        "                        cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                        cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "                        center = (cx, cy)\n",
        "\n",
        "                        # Обновляем траекторию\n",
        "                        if current_segment:\n",
        "                            last_x, last_y = current_segment[-1]\n",
        "                            distance = math.sqrt((cx - last_x)**2 + (cy - last_y)**2)\n",
        "\n",
        "                            if distance <= max_line_length:\n",
        "                                current_segment.append(center)\n",
        "                            else:\n",
        "                                # Сохраняем текущий сегмент и начинаем новый\n",
        "                                if len(current_segment) > 1:\n",
        "                                    full_trajectory.append(current_segment)\n",
        "                                current_segment = [center]\n",
        "                        else:\n",
        "                            current_segment.append(center)\n",
        "\n",
        "                        # Рисуем контур объекта\n",
        "                        cv2.drawContours(frame, [hull], -1, (0,255,0), 2)\n",
        "\n",
        "                        # Рисуем центр маленьким квадратом\n",
        "                        cv2.rectangle(frame, (cx-3, cy-3), (cx+3, cy+3), (0,0,255), -1)\n",
        "\n",
        "        # Рисуем всю историю траектории\n",
        "        for segment in full_trajectory:\n",
        "            for i in range(1, len(segment)):\n",
        "                cv2.line(frame, segment[i-1], segment[i], (255,0,0), 2)\n",
        "\n",
        "        # Рисуем текущий сегмент\n",
        "        if len(current_segment) > 1:\n",
        "            for i in range(1, len(current_segment)):\n",
        "                cv2.line(frame, current_segment[i-1], current_segment[i], (255,0,0), 2)\n",
        "\n",
        "        object_writer.write(object_frame)\n",
        "        trajectory_writer.write(frame)\n",
        "        prev_gray = gray.copy()\n",
        "\n",
        "    # Сохраняем последний сегмент\n",
        "    if len(current_segment) > 1:\n",
        "        full_trajectory.append(current_segment)\n",
        "\n",
        "    cap.release()\n",
        "    trajectory_writer.release()\n",
        "    object_writer.release()\n",
        "\n",
        "# Пример использования\n",
        "input_filename = '/content/CV_LB3/Мышка.mp4'\n",
        "process_video(input_filename,\n",
        "             max_line_length=150,\n",
        "             min_object_area=10000,\n",
        "             max_object_area=60000,\n",
        "             detection_region_y=200)\n",
        "\"\"\"\n",
        "process_video(input_filename,\n",
        "             max_line_length=150,\n",
        "             min_object_area=3000,\n",
        "             max_object_area=14000,\n",
        "             detection_region_y=200)\n",
        "\"\"\"\n",
        "files.download('trajectory.mp4')\n",
        "files.download('object.mp4')"
      ],
      "metadata": {
        "id": "6uSr244Ba3VW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Метод для видео 2\n",
        "def labels_pro(labels, t):\n",
        "    d = {}\n",
        "    for i, row in enumerate(labels[0]):\n",
        "      for j, pix in enumerate(row):\n",
        "        if pix not in d:\n",
        "          d[pix] = [i, i, j, j, 1]\n",
        "        else:\n",
        "          cur = d[pix]\n",
        "          cur[4] += 1\n",
        "          if i < cur[0]:\n",
        "            cur[0] = i\n",
        "          if i > cur[1]:\n",
        "            cur[1] = i\n",
        "          if j < cur[2]:\n",
        "            cur[2] = j\n",
        "          if j > cur[3]:\n",
        "            cur[3] = j\n",
        "\n",
        "\n",
        "    return {k: v for k, v in d.items() if v[4] > t}\n",
        "\n",
        "def rgb_to_grayscale(img):\n",
        "    return (img[:,:,0]*0.299 + img[:,:,1]*0.587 + img[:,:,2]*0.114).astype(np.uint8)\n",
        "\n",
        "def distance(a, b):\n",
        "  return math.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n",
        "\n",
        "def frame_diff(prev, curr, threshold=25):\n",
        "    diff = np.abs(prev.astype(int) - curr.astype(int))\n",
        "    return (diff > threshold).astype(np.uint8) * 255\n",
        "\n",
        "def process_video(input_path,\n",
        "                 max_line_length=200,\n",
        "                 min_object_area=200,\n",
        "                 max_object_area=5000,\n",
        "                 detection_region_y=None):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Ошибка открытия видеофайла\")\n",
        "        return\n",
        "\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    trajectory_writer = cv2.VideoWriter('trajectory.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    object_writer = cv2.VideoWriter('object.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    prev_gray = None\n",
        "    full_trajectory = []  # Хранит все точки траектории\n",
        "    boxes = []   # Текущий непрерывный сегмент\n",
        "\n",
        "    last_watched_anime = None\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.GaussianBlur(rgb_to_grayscale(frame), (5,5), 0)\n",
        "        gray = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "        #cv2_imshow(gray)\n",
        "\n",
        "        labeled_image = label(gray)\n",
        "        num_labels = labeled_image[1]\n",
        "\n",
        "        cv2_imshow(labeled_image[0])\n",
        "\n",
        "        #anime_girls = labels_pro(labeled_image, 25000)\n",
        "        anime_girls = labels_pro(labeled_image, 18000)\n",
        "\n",
        "        #print(anime_girls)\n",
        "\n",
        "        object_frame = np.zeros_like(frame)\n",
        "\n",
        "        if last_watched_anime is not None:\n",
        "          for k, v in last_watched_anime.items():\n",
        "            center = (int((v[2] + v[3]) / 2),int((v[0] + v[1]) / 2))\n",
        "            least_distant_point = None\n",
        "            for k1, v1 in anime_girls.items():\n",
        "              center1 = (int((v1[2] + v1[3]) / 2),int((v1[0] + v1[1]) / 2))\n",
        "              if least_distant_point is None:\n",
        "                least_distant_point = center1\n",
        "                continue\n",
        "              if distance(center, center1) < distance(least_distant_point, center):\n",
        "                least_distant_point = center1\n",
        "          #cv2.rectangle(frame, (v[1], v[2]), (v[3], v[0]), (0, 0, 255), 2)\n",
        "          if distance(center, least_distant_point) < 600:\n",
        "            full_trajectory.append([center, least_distant_point])\n",
        "        last_watched_anime = anime_girls\n",
        "\n",
        "        # Рисуем всю историю траектории\n",
        "        for segment in full_trajectory:\n",
        "          #print(segment[0])\n",
        "          #print(segment[1])\n",
        "          cv2.line(frame, segment[0], segment[1], (255,0,0), 2)\n",
        "\n",
        "\n",
        "        object_writer.write(object_frame)\n",
        "        trajectory_writer.write(frame)\n",
        "        prev_gray = gray.copy()\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    trajectory_writer.release()\n",
        "    object_writer.release()\n",
        "\n",
        "# Пример использования\n",
        "input_filename = '/content/CV_LB3/Мышка2.mp4'\n",
        "process_video(input_filename,\n",
        "             max_line_length=150,\n",
        "             min_object_area=3000,\n",
        "             max_object_area=14000,\n",
        "             detection_region_y=200)\n",
        "\n",
        "files.download('trajectory.mp4')"
      ],
      "metadata": {
        "id": "rDXSa5cWTnlV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}